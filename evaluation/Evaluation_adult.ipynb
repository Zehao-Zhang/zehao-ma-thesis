{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1594,"status":"ok","timestamp":1734430442414,"user":{"displayName":"张泽昊","userId":"04308898238357121257"},"user_tz":-60},"id":"ipO1HwFWCk0B","outputId":"c8e0341e-e650-41b6-9432-35f550604745"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Colab Notebooks/synprivutil-main\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/Colab Notebooks/synprivutil-main"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":3061,"status":"ok","timestamp":1734430445473,"user":{"displayName":"张泽昊","userId":"04308898238357121257"},"user_tz":-60},"id":"TygU6ZiUD8V6","outputId":"78bcef5b-c369-4907-abee-b8afbac6a356"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.10/dist-packages (1.26.4)\n","Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: sdv==1.15.0 in /usr/local/lib/python3.10/dist-packages (1.15.0)\n","Requirement already satisfied: scikit-learn==1.5.1 in /usr/local/lib/python3.10/dist-packages (1.5.1)\n","Requirement already satisfied: seaborn==0.12.2 in /usr/local/lib/python3.10/dist-packages (0.12.2)\n","Requirement already satisfied: matplotlib==3.9.2 in /usr/local/lib/python3.10/dist-packages (3.9.2)\n","Requirement already satisfied: rdt==1.12.3 in /usr/local/lib/python3.10/dist-packages (1.12.3)\n","Requirement already satisfied: anonymeter==1.0.0 in /usr/local/lib/python3.10/dist-packages (1.0.0)\n","Requirement already satisfied: scipy==1.13.0 in /usr/local/lib/python3.10/dist-packages (1.13.0)\n","Requirement already satisfied: dython==0.7.8 in /usr/local/lib/python3.10/dist-packages (0.7.8)\n","Requirement already satisfied: POT==0.9.4 in /usr/local/lib/python3.10/dist-packages (0.9.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2) (2024.2)\n","Requirement already satisfied: boto3>=1.28 in /usr/local/lib/python3.10/dist-packages (from sdv==1.15.0) (1.35.82)\n","Requirement already satisfied: botocore>=1.31 in /usr/local/lib/python3.10/dist-packages (from sdv==1.15.0) (1.35.82)\n","Requirement already satisfied: cloudpickle>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from sdv==1.15.0) (3.1.0)\n","Requirement already satisfied: graphviz>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from sdv==1.15.0) (0.20.3)\n","Requirement already satisfied: tqdm>=4.29 in /usr/local/lib/python3.10/dist-packages (from sdv==1.15.0) (4.66.6)\n","Requirement already satisfied: copulas>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from sdv==1.15.0) (0.12.0)\n","Requirement already satisfied: ctgan>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from sdv==1.15.0) (0.10.2)\n","Requirement already satisfied: deepecho>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from sdv==1.15.0) (0.6.1)\n","Requirement already satisfied: sdmetrics>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from sdv==1.15.0) (0.18.0)\n","Requirement already satisfied: platformdirs>=4.0 in /usr/local/lib/python3.10/dist-packages (from sdv==1.15.0) (4.3.6)\n","Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from sdv==1.15.0) (6.0.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.1) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.1) (3.5.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.2) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.2) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.2) (4.55.3)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.2) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.2) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.2) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.2) (3.2.0)\n","Requirement already satisfied: Faker>=17 in /usr/local/lib/python3.10/dist-packages (from rdt==1.12.3) (33.1.0)\n","Requirement already satisfied: numba~=0.58 in /usr/local/lib/python3.10/dist-packages (from anonymeter==1.0.0) (0.60.0)\n","Requirement already satisfied: psutil>=5.9.1 in /usr/local/lib/python3.10/dist-packages (from dython==0.7.8) (5.9.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dython==0.7.8) (75.1.0)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.28->sdv==1.15.0) (1.0.1)\n","Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.28->sdv==1.15.0) (0.10.4)\n","Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore>=1.31->sdv==1.15.0) (2.2.3)\n","Requirement already satisfied: plotly>=5.10.0 in /usr/local/lib/python3.10/dist-packages (from copulas>=0.11.0->sdv==1.15.0) (5.24.1)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from ctgan>=0.10.0->sdv==1.15.0) (2.5.1+cu121)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from Faker>=17->rdt==1.12.3) (4.12.2)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba~=0.58->anonymeter==1.0.0) (0.43.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.10.0->copulas>=0.11.0->sdv==1.15.0) (9.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan>=0.10.0->sdv==1.15.0) (3.16.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan>=0.10.0->sdv==1.15.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan>=0.10.0->sdv==1.15.0) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan>=0.10.0->sdv==1.15.0) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan>=0.10.0->sdv==1.15.0) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->ctgan>=0.10.0->sdv==1.15.0) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->ctgan>=0.10.0->sdv==1.15.0) (3.0.2)\n"]}],"source":["!pip install numpy==1.26.4 pandas==2.2.2 sdv==1.15.0 scikit-learn==1.5.1 seaborn==0.12.2 matplotlib==3.9.2 rdt==1.12.3 anonymeter==1.0.0 scipy==1.13.0 dython==0.7.8 POT==0.9.4\n"]},{"cell_type":"markdown","metadata":{"id":"IKivqkgQ9mvI"},"source":["## ML utility"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":536,"status":"ok","timestamp":1734377609699,"user":{"displayName":"张泽昊","userId":"04308898238357121257"},"user_tz":-60},"id":"6yJ39597Bivg"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.metrics import f1_score, accuracy_score\n","import numpy as np\n","\n","def calculate_ml_utility_classification(original, synthetic, target_column):\n","    \"\"\"\n","    Evaluate machine learning utility by linking synthetic data to original data\n","    using classification models and calculating average F1 score and accuracy.\n","\n","    Parameters:\n","        original (pd.DataFrame): Original dataset.\n","        synthetic (pd.DataFrame): Synthetic dataset.\n","        target_column (str): The target column for classification.\n","\n","    Returns:\n","        dict: Average F1 score and accuracy for STO scenario across multiple classifiers.\n","    \"\"\"\n","    # Step 1: Prepare original data\n","    X_test_orig = original.drop(columns=[target_column])\n","    y_test_orig = original[target_column]\n","\n","    # Step 2: Prepare synthetic data\n","    X_syn = synthetic.drop(columns=[target_column])\n","    y_syn = synthetic[target_column]\n","\n","    # Classification models\n","    models = [RandomForestClassifier(), GradientBoostingClassifier()]\n","\n","    # Collect scores for STO (Train on Synthetic, Test on Original)\n","    sto_f1_list = []\n","    sto_accuracy_list = []\n","\n","    for model in models:\n","        # Train on synthetic data, test on original data\n","        model.fit(X_syn, y_syn)\n","        y_pred_syn_on_orig = model.predict(X_test_orig)\n","\n","        # Calculate F1 score and accuracy\n","        sto_f1 = f1_score(y_test_orig, y_pred_syn_on_orig, average='weighted')\n","        sto_accuracy = accuracy_score(y_test_orig, y_pred_syn_on_orig)\n","\n","        sto_f1_list.append(sto_f1)\n","        sto_accuracy_list.append(sto_accuracy)\n","\n","    # Average scores\n","    avg_sto_f1 = np.mean(sto_f1_list)\n","    avg_sto_accuracy = np.mean(sto_accuracy_list)\n","\n","    metrics = {\n","        \"F1_syn\": avg_sto_f1,  # Train on synthetic, test on original\n","        \"Accuracy_syn\": avg_sto_accuracy  # Train on synthetic, test on original\n","    }\n","\n","    return metrics\n","\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":815,"status":"ok","timestamp":1734385528083,"user":{"displayName":"张泽昊","userId":"04308898238357121257"},"user_tz":-60},"id":"uyK5cLFkXejm"},"outputs":[],"source":["def replace_outliers_with_mean(original_data, synthetic_data, synthetic_name, threshold=1):\n","    total_replacements = 0  # Initialize replacement count\n","\n","    for column in synthetic_data.columns:\n","        if column in original_data.columns:\n","            # Use max and min with std range to determine abnormal value\n","            orig_mean = original_data[column].median()\n","            orig_max = original_data[column].max()\n","            orig_min = original_data[column].min()\n","            orig_std = original_data[column].std()\n","\n","            lower_bound = orig_min - threshold * orig_std\n","            upper_bound = orig_max + threshold * orig_std\n","\n","            # Replace and count\n","            replaced_column = synthetic_data[column].apply(\n","                lambda x: orig_mean if x < lower_bound or x > upper_bound else x\n","            )\n","\n","            # Count the number of replaced values\n","            replacements = (synthetic_data[column] != replaced_column).sum()\n","            total_replacements += replacements\n","\n","            # Update column data\n","            synthetic_data[column] = replaced_column\n","\n","    print(f\"Under {synthetic_name} total replacements made: {total_replacements}\")\n","    return synthetic_data\n","\n","def remove_rows_with_outliers(original_data, synthetic_data, synthetic_name, threshold=1):\n","  \n","    # Initialize set of rows to drop\n","    rows_to_drop = set()\n","\n","    for column in synthetic_data.columns:\n","        if column in original_data.columns:\n","            # Calculate range based on original data\n","            orig_mean = original_data[column].median()\n","            orig_max = original_data[column].max()\n","            orig_min = original_data[column].min()\n","            orig_std = original_data[column].std()\n","\n","            lower_bound = orig_min - threshold * orig_std\n","            upper_bound = orig_max + threshold * orig_std\n","\n","            # Find rows with outliers\n","            outlier_indices = synthetic_data[(synthetic_data[column] < lower_bound) |\n","                                             (synthetic_data[column] > upper_bound)].index\n","            rows_to_drop.update(outlier_indices)\n","\n","            \n","    rows_to_drop = list(rows_to_drop)  # Convert to list for deletion\n","    cleaned_data = synthetic_data.drop(index=rows_to_drop)\n","\n","    print(f\"Under {synthetic_name}, removed {len(rows_to_drop)} rows with outliers.\")\n","    return cleaned_data\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":233},"collapsed":true,"executionInfo":{"elapsed":2965,"status":"error","timestamp":1734385535881,"user":{"displayName":"张泽昊","userId":"04308898238357121257"},"user_tz":-60},"id":"XKZo1TyD9O1n","outputId":"afa8d863-83bb-4e49-b855-bebe06d1e9e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Under 0.25, removed 3652 rows with outliers.\n"]},{"ename":"NameError","evalue":"name 'calculate_ml_utility_classification' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-b00c1b96b723>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Step 1: Calculate ML utility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mml_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_ml_utility_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynthetic_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# Step 2: Add metrics to aggregated_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'calculate_ml_utility_classification' is not defined"]}],"source":["import os\n","import re\n","import gc\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from collections import defaultdict\n","from sklearn.preprocessing import MinMaxScaler\n","# Load original dataset\n","original_data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Tabula-main-claude/Real_Datasets/adult_test.csv\")\n","original_name = \"adult\"\n","\n","# Directory containing synthetic datasets\n","synthetic_folder = \"/content/drive/MyDrive/Colab Notebooks/Tabula-main-claude/adult_syn_data\"\n","\n","# Dictionary to store aggregated results\n","aggregated_results = defaultdict(lambda: defaultdict(list))\n","\n","# Function to extract sigma value as float\n","def extract_sigma(file_name):\n","    match = re.search(r\"sigma-(\\d+)\", file_name)\n","    if match:\n","        sigma_str = match.group(1)\n","        if len(sigma_str) == 1:  # Single digit like \"1\" -> \"1\"\n","            return int(sigma_str)\n","        elif len(sigma_str) == 2:  # Two digits like \"05\" -> \"0.5\"\n","            return int(sigma_str) / 10\n","        elif len(sigma_str) == 3:  # Three digits like \"005\" -> \"0.05\"\n","            return int(sigma_str) / 100\n","    return None\n","\n","target_column = \"income\"  # Replace with your actual target column\n","task_type = \"classification\"  # \"classification\" or \"regression\"\n","\n","# Loop through each synthetic file and perform calculations\n","for file_name in os.listdir(synthetic_folder):\n","    if file_name.endswith(\".csv\"):\n","        synthetic_path = os.path.join(synthetic_folder, file_name)\n","        synthetic_data = pd.read_csv(synthetic_path)\n","\n","        # Ensure correct data types (e.g., convert 'age' column to int if needed)\n","        # if 'age' in synthetic_data.columns:\n","        #     synthetic_data['age'] = synthetic_data['age'].astype(int)\n","\n","        for column in synthetic_data.columns:\n","            if column in original_data.columns:\n","                # Convert the column type in synthetic data to match the original data\n","                synthetic_data[column] = synthetic_data[column].astype(original_data[column].dtype)\n","\n","        sigma = extract_sigma(file_name)\n","        if sigma is None:\n","            continue  # Skip files without a valid sigma value\n","        # print(f\"\\nProcessing synthetic dataset: {file_name} (sigma: {sigma})\")\n","        # synthetic_data = replace_outliers_with_mean(original_data, synthetic_data, sigma)\n","        synthetic_data = remove_rows_with_outliers(original_data, synthetic_data, sigma)\n","\n","        # Step 1: Calculate ML utility\n","        ml_results = calculate_ml_utility_classification(original_data, synthetic_data, target_column)\n","\n","        # Step 2: Add metrics to aggregated_results\n","        for category, metric_value in ml_results.items():\n","            aggregated_results[sigma][category].append(metric_value)\n","\n","        # Cleanup\n","        del synthetic_data\n","        gc.collect()\n","\n","\n","\n","# Step 3: Calculate average metrics for each sigma\n","averaged_results = defaultdict(dict)\n","for sigma, metrics in aggregated_results.items():\n","    for metric, values in metrics.items():\n","        averaged_results[sigma][metric] = np.mean(values)\n","\n","# Step 4: Convert averaged_results into a DataFrame\n","final_results = defaultdict(list)\n","for sigma, metrics in averaged_results.items():\n","    final_results[\"sigma\"].append(sigma)\n","    for metric, value in metrics.items():\n","        final_results[metric].append(value)\n","\n","df = pd.DataFrame(final_results)\n","\n","# Sort the DataFrame by sigma\n","df = df.sort_values(by=\"sigma\").reset_index(drop=True)\n","\n","# Step 5: Print and verify the DataFrame\n","print(df)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MjURR78t9QwT"},"source":["## Privacy and utility evaluations"]},{"cell_type":"markdown","metadata":{"id":"BQBGoFaxMlE9"},"source":["### original"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"H8nWNgLUgteB"},"outputs":[],"source":["import os\n","import re\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from collections import defaultdict\n","from sklearn.preprocessing import MinMaxScaler\n","from privacy_utility_framework.privacy_utility_framework.metrics.utility_metrics.utility_metric_manager import UtilityMetricManager\n","from privacy_utility_framework.privacy_utility_framework.metrics.utility_metrics.statistical.basic_stats import BasicStatsCalculator\n","from privacy_utility_framework.privacy_utility_framework.metrics.utility_metrics.statistical.mutual_information import MICalculator\n","from privacy_utility_framework.privacy_utility_framework.metrics.utility_metrics.statistical.correlation import CorrelationCalculator\n","from privacy_utility_framework.privacy_utility_framework.metrics.utility_metrics.statistical.js_similarity import JSCalculator\n","from privacy_utility_framework.privacy_utility_framework.metrics.privacy_metrics.privacy_metric_manager import PrivacyMetricManager\n","from privacy_utility_framework.privacy_utility_framework.metrics.privacy_metrics.distance.adversarial_accuracy_class import AdversarialAccuracyCalculator, AdversarialAccuracyCalculator_NN\n","from privacy_utility_framework.privacy_utility_framework.metrics.privacy_metrics.distance.dcr_class import DCRCalculator\n","from privacy_utility_framework.privacy_utility_framework.metrics.privacy_metrics.distance.nndr_class import NNDRCalculator\n","from privacy_utility_framework.privacy_utility_framework.metrics.privacy_metrics.distance.disco import DisclosureCalculator\n","\n","# Load original dataset\n","original_data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Tabula-main-claude/Real_Datasets/Adult.csv\")\n","# original_data.drop(columns=[\"index\"], inplace=True)\n","# original_data.drop(columns=[\"id\"], inplace=True)\n","original_name = \"adult\"\n","\n","# Directory containing synthetic datasets\n","synthetic_folder = \"/content/drive/MyDrive/Colab Notebooks/Tabula-main-claude/adult_syn_data\"\n","\n","# Dictionary to store aggregated results\n","aggregated_results = defaultdict(lambda: defaultdict(list))\n","\n","# Function to extract sigma value as float\n","def extract_sigma(file_name):\n","    match = re.search(r\"sigma-(\\d+)\", file_name)\n","    if match:\n","        sigma_str = match.group(1)\n","        if len(sigma_str) == 1:  # Single digit like \"1\" -> \"1\"\n","            return int(sigma_str)\n","        elif len(sigma_str) == 2:  # Two digits like \"05\" -> \"0.5\"\n","            return int(sigma_str) / 10\n","        elif len(sigma_str) == 3:  # Three digits like \"005\" -> \"0.05\"\n","            return int(sigma_str) / 100\n","    return None\n","\n","\n","# Loop through each synthetic file and perform calculations\n","for file_name in os.listdir(synthetic_folder):\n","    if file_name.endswith(\".csv\"):\n","        synthetic_path = os.path.join(synthetic_folder, file_name)\n","        synthetic_data = pd.read_csv(synthetic_path)\n","\n","        sigma = extract_sigma(file_name)\n","        if sigma is None:\n","            continue  # Skip files without a valid sigma value\n","\n","        # synthetic_data = replace_outliers_with_mean(original_data, synthetic_data, sigma)\n","        # synthetic_data = remove_rows_with_outliers(original_data, synthetic_data, sigma)\n","        # Ensure correct data types (e.g., convert 'age' column to int if needed)\n","        for column in synthetic_data.columns:\n","            if column in original_data.columns:\n","                # Convert the column type in synthetic data to match the original data\n","                synthetic_data[column] = synthetic_data[column].astype(original_data[column].dtype)\n","\n","\n","        # print(f\"\\nProcessing synthetic dataset: {file_name} (sigma: {sigma})\")\n","\n","        # Utility Metric Calculation\n","        u = UtilityMetricManager()\n","        utility_metric_list = [\n","            # BasicStatsCalculator(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","            # MICalculator(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","            # CorrelationCalculator(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","            JSCalculator(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","        ]\n","        u.add_metric(utility_metric_list)\n","        results_utility = u.evaluate_all()\n","\n","        # Privacy Metric Calculation\n","        p = PrivacyMetricManager()\n","        privacy_metric_list = [\n","            # DCRCalculator(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","            # NNDRCalculator(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","            # AdversarialAccuracyCalculator_NN(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","            # AdversarialAccuracyCalculator(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","        ]\n","        p.add_metric(privacy_metric_list)\n","        results_privacy = p.evaluate_all()\n","\n","        # # DiSCO and repU\n","        # adult_keys = ['age', 'workclass', 'education', 'marital-status',\n","        #               'occupation', 'relationship', 'race', 'gender', 'capital-gain',\n","        #               'capital-loss', 'hours-per-week', 'native-country']\n","        # adult_target = 'income'  \n","\n","        # calc = DisclosureCalculator(original_data, synthetic_data, keys=adult_keys, target=adult_target)\n","        # repU, DiSCO = calc.evaluate()\n","\n","        # Aggregate metrics\n","        for key, value in {**results_utility, **results_privacy}.items():\n","            aggregated_results[sigma][key].append(value)\n","\n","\n","        # aggregated_results[sigma][\"Disclosure_repU\"].append(repU)\n","        # aggregated_results[sigma][\"Disclosure_DiSCO\"].append(DiSCO)\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":351,"status":"ok","timestamp":1734384728455,"user":{"displayName":"张泽昊","userId":"04308898238357121257"},"user_tz":-60},"id":"GVmYdrKLEwVR"},"outputs":[],"source":["import numpy as np\n","# Calculate average metrics for each sigma\n","averaged_results = defaultdict(dict)\n","for sigma, metrics in aggregated_results.items():\n","    for metric, values in metrics.items():\n","        if isinstance(values[0], dict):\n","            averaged_results[sigma][metric] = {k: np.mean([v[k] for v in values]) for k in values[0]}\n","        else:\n","            averaged_results[sigma][metric] = np.mean(values)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":337,"status":"ok","timestamp":1734384782388,"user":{"displayName":"张泽昊","userId":"04308898238357121257"},"user_tz":-60},"id":"Hrh-dnRqfCrF","outputId":"30a5574f-89ce-4c93-8a8d-275c562abf2c"},"outputs":[{"name":"stdout","output_type":"stream","text":["    sigma          DCR      NNDR      NNAA\n","0    0.00     0.193052  0.904975  0.973265\n","1    0.01     0.389098  0.749186  0.647102\n","2    0.02     1.236993  0.771475  0.681537\n","3    0.03     1.059227  0.913428  0.967602\n","4    0.04     1.761422  0.890156  0.977859\n","5    0.05    12.224539  0.916962  0.969869\n","6    0.10     4.492382  0.914446  0.980744\n","7    0.15     9.979821  0.912635  0.984878\n","8    0.20    27.527854  0.884207  0.857258\n","9    0.25    59.524123  0.887548  0.867388\n","10   0.30   239.945031  0.933274  0.972152\n","11   0.35  2903.472714  0.924814  0.980547\n"]}],"source":["# Clean up averaged_results to extract metric names without file details\n","cleaned_results = defaultdict(dict)\n","\n","for sigma, metrics in averaged_results.items():\n","    for metric, value in metrics.items():\n","        # Extract only the metric name, ignoring dataset/file info\n","        metric_name = metric.split(\"(\")[0]\n","        if metric_name not in cleaned_results[sigma]:\n","            cleaned_results[sigma][metric_name] = []\n","        cleaned_results[sigma][metric_name].append(value)\n","\n","# Aggregate and calculate average values for cleaned results\n","final_results = defaultdict(dict)\n","for sigma, metrics in cleaned_results.items():\n","    for metric, values in metrics.items():\n","        if isinstance(values[0], dict):  # If metric value is a dictionary\n","            # Average each key in the dictionary\n","            final_results[sigma][metric] = {k: sum(v[k] for v in values) / len(values) for k in values[0]}\n","        else:  # If metric value is a list of scalars\n","            final_results[sigma][metric] = sum(values) / len(values)\n","\n","# Prepare data for plotting\n","data = {\n","    \"sigma\": sorted(final_results.keys()),\n","    \"DCR\": [final_results[sigma].get(\"DCRCalculator\", None) for sigma in sorted(final_results.keys())],\n","    \"NNDR\": [final_results[sigma].get(\"NNDRCalculator\", None) for sigma in sorted(final_results.keys())],\n","    # \"AdversarialAccuracy\": [final_results[sigma].get(\"AdversarialAccuracyCalculator\", None) for sigma in sorted(final_results.keys())],\n","    \"NNAA\": [final_results[sigma].get(\"AdversarialAccuracyCalculator_NN\", None) for sigma in sorted(final_results.keys())],\n","    # \"Correlation\": [final_results[sigma].get(\"CorrelationCalculator\", None) for sigma in sorted(final_results.keys())],\n","    # \"JS\": [final_results[sigma].get(\"JSCalculator\", None) for sigma in sorted(final_results.keys())],\n","    # \"repU\": [final_results[sigma].get(\"Disclosure_repU\", None) for sigma in sorted(final_results.keys())],\n","    # \"DiSCO\": [final_results[sigma].get(\"Disclosure_DiSCO\", None) for sigma in sorted(final_results.keys())],\n","}\n","\n","# Convert to DataFrame\n","df = pd.DataFrame(data)\n","\n","# Verify DataFrame content\n","print(df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"iAUsyWF7tRP7","outputId":"7a7301d8-4be9-496e-c5e7-d4f1a444f72c"},"outputs":[{"name":"stdout","output_type":"stream","text":["    sigma        mean    median           var\n","0    0.25    4.252804  0.008968  1.901838e+06\n","1    0.01    0.039493  0.006569  4.921741e+01\n","2    0.05    0.894432  0.037042  2.620480e+05\n","3    0.10    0.339570  0.034717  9.922552e+02\n","4    0.15    0.734234  0.053231  1.262529e+04\n","5    0.20    1.969232  0.006718  1.777147e+05\n","6    0.30   17.155943  0.044074  2.698867e+07\n","7    0.35  207.408274  0.040310  1.882297e+10\n","8    0.02    0.100999  0.001715  2.473936e+02\n","9    0.03    0.095960  0.036591  1.581677e+02\n","10   0.04    0.145646  0.032641  2.693895e+02\n","11   0.00    0.040607  0.051116  2.027713e-02\n"]}],"source":["# 提取 BasicStatsCalculator 的 mean、median、var\n","basic_stats_data = {\n","    \"sigma\": [],\n","    \"mean\": [],\n","    \"median\": [],\n","    \"var\": []\n","}\n","\n","for sigma, metrics in final_results.items():\n","    if \"BasicStatsCalculator\" in metrics:\n","        basic_stats = metrics[\"BasicStatsCalculator\"]\n","        basic_stats_data[\"sigma\"].append(sigma)\n","        basic_stats_data[\"mean\"].append(basic_stats[\"mean\"])\n","        basic_stats_data[\"median\"].append(basic_stats[\"median\"])\n","        basic_stats_data[\"var\"].append(basic_stats[\"var\"])\n","\n","# 转换为 DataFrame\n","basic_stats_df = pd.DataFrame(basic_stats_data)\n","\n","# 显示结果\n","print(basic_stats_df)\n"]},{"cell_type":"markdown","metadata":{"id":"fm4RCirVMeBa"},"source":["### replace"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":2062511,"status":"ok","timestamp":1734286643892,"user":{"displayName":"张泽昊","userId":"04308898238357121257"},"user_tz":-60},"id":"Kv3vFP1OMpVQ","outputId":"ed92fbab-e590-429f-974f-25534c9cc5cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Under 0.25 total replacements made: 3687\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 72549 columns.\n","IDENTITY: \n","         UiO        UiS     UiOiS      repU\n","0  77.122149  78.097907  1.924573  1.394292\n","ATTRIBUTES: \n","       Dorig       Dsyn        iS       DiS     DiSCO    DiSDiO  max_denom  \\\n","0  92.070349  88.360093  8.574587  6.396134  4.309815  2.741493       20.0   \n","\n","   mean_denom  \n","0     1.96729  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n","Under 0.01 total replacements made: 378\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 62948 columns.\n","IDENTITY: \n","         UiO        UiS     UiOiS      repU\n","0  77.122149  54.282636  5.691823  3.527702\n","ATTRIBUTES: \n","       Dorig       Dsyn         iS        DiS      DiSCO    DiSDiO  max_denom  \\\n","0  92.070349  75.834857  20.058556  13.181278  10.910692  9.854224       19.0   \n","\n","   mean_denom  \n","0    1.711854  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n","Under 0.05 total replacements made: 1771\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 71680 columns.\n","IDENTITY: \n","         UiO        UiS     UiOiS     repU\n","0  77.122149  66.430302  0.014332  0.00819\n","ATTRIBUTES: \n","       Dorig       Dsyn        iS      DiS     DiSCO    DiSDiO  max_denom  \\\n","0  92.070349  79.602806  0.014332  0.00819  0.006142  0.006142        1.0   \n","\n","   mean_denom  \n","0         1.0  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n","Under 0.1 total replacements made: 2689\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 73987 columns.\n","IDENTITY: \n","         UiO        UiS     UiOiS      repU\n","0  77.122149  74.342442  0.004095  0.002047\n","ATTRIBUTES: \n","       Dorig      Dsyn        iS       DiS     DiSCO    DiSDiO  max_denom  \\\n","0  92.070349  85.62839  0.004095  0.002047  0.002047  0.002047        1.0   \n","\n","   mean_denom  \n","0         1.0  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n","Under 0.15 total replacements made: 3102\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 74573 columns.\n","IDENTITY: \n","         UiO        UiS     UiOiS      repU\n","0  77.122149  77.021112  0.006142  0.006142\n","ATTRIBUTES: \n","       Dorig       Dsyn        iS       DiS     DiSCO    DiSDiO  max_denom  \\\n","0  92.070349  87.206488  0.012285  0.012285  0.010237  0.006142        2.0   \n","\n","   mean_denom  \n","0        1.25  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n","Under 0.2 total replacements made: 3343\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 72535 columns.\n","IDENTITY: \n","         UiO        UiS     UiOiS      repU\n","0  77.122149  77.458867  2.098604  1.568322\n","ATTRIBUTES: \n","       Dorig       Dsyn        iS       DiS     DiSCO    DiSDiO  max_denom  \\\n","0  92.070349  87.956091  9.139675  6.658204  4.547316  3.165309       18.0   \n","\n","   mean_denom  \n","0    1.874262  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n","Under 0.3 total replacements made: 4011\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 74627 columns.\n","IDENTITY: \n","         UiO        UiS    UiOiS      repU\n","0  77.122149  80.042211  0.00819  0.006142\n","ATTRIBUTES: \n","       Dorig       Dsyn       iS       DiS     DiSCO    DiSDiO  max_denom  \\\n","0  92.070349  90.117399  0.00819  0.006142  0.004095  0.004095        1.0   \n","\n","   mean_denom  \n","0         1.0  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n","Under 0.35 total replacements made: 4446\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 74623 columns.\n","IDENTITY: \n","         UiO        UiS     UiOiS      repU\n","0  77.122149  81.880525  0.004095  0.004095\n","ATTRIBUTES: \n","       Dorig       Dsyn        iS       DiS     DiSCO    DiSDiO  max_denom  \\\n","0  92.070349  91.023306  0.004095  0.004095  0.002047  0.002047        1.0   \n","\n","   mean_denom  \n","0         1.0  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n","Under 0.02 total replacements made: 773\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 65107 columns.\n","IDENTITY: \n","         UiO        UiS     UiOiS      repU\n","0  77.122149  58.873374  5.007985  3.105933\n","ATTRIBUTES: \n","       Dorig       Dsyn         iS        DiS     DiSCO    DiSDiO  max_denom  \\\n","0  92.070349  75.429316  17.781827  10.992588  8.777282  7.880513       19.0   \n","\n","   mean_denom  \n","0    1.718236  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n","Under 0.03 total replacements made: 1144\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 70344 columns.\n","IDENTITY: \n","         UiO        UiS     UiOiS      repU\n","0  77.122149  62.321388  0.022522  0.014332\n","ATTRIBUTES: \n","       Dorig       Dsyn        iS       DiS     DiSCO    DiSDiO  max_denom  \\\n","0  92.070349  77.268276  0.022522  0.020474  0.016379  0.016379        1.0   \n","\n","   mean_denom  \n","0         1.0  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n","Under 0.04 total replacements made: 1416\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 71173 columns.\n","IDENTITY: \n","         UiO        UiS     UiOiS      repU\n","0  77.122149  64.949077  0.006142  0.006142\n","ATTRIBUTES: \n","       Dorig       Dsyn        iS       DiS     DiSCO    DiSDiO  max_denom  \\\n","0  92.070349  78.317536  0.020474  0.020474  0.010237  0.010237        2.0   \n","\n","   mean_denom  \n","0        1.25  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n","Under 0 total replacements made: 36\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 66512 columns.\n","IDENTITY: \n","         UiO        UiS     UiOiS      repU\n","0  77.122149  38.186764  0.020474  0.014332\n","ATTRIBUTES: \n","       Dorig       Dsyn        iS       DiS     DiSCO    DiSDiO  max_denom  \\\n","0  92.070349  71.653433  0.020474  0.016379  0.016379  0.016379        1.0   \n","\n","   mean_denom  \n","0         1.0  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n"]}],"source":["import os\n","import re\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from collections import defaultdict\n","from sklearn.preprocessing import MinMaxScaler\n","from privacy_utility_framework.privacy_utility_framework.metrics.utility_metrics.utility_metric_manager import UtilityMetricManager\n","from privacy_utility_framework.privacy_utility_framework.metrics.utility_metrics.statistical.basic_stats import BasicStatsCalculator\n","from privacy_utility_framework.privacy_utility_framework.metrics.utility_metrics.statistical.mutual_information import MICalculator\n","from privacy_utility_framework.privacy_utility_framework.metrics.utility_metrics.statistical.correlation import CorrelationCalculator\n","from privacy_utility_framework.privacy_utility_framework.metrics.utility_metrics.statistical.js_similarity import JSCalculator\n","from privacy_utility_framework.privacy_utility_framework.metrics.privacy_metrics.privacy_metric_manager import PrivacyMetricManager\n","from privacy_utility_framework.privacy_utility_framework.metrics.privacy_metrics.distance.adversarial_accuracy_class import AdversarialAccuracyCalculator, AdversarialAccuracyCalculator_NN\n","from privacy_utility_framework.privacy_utility_framework.metrics.privacy_metrics.distance.dcr_class import DCRCalculator\n","from privacy_utility_framework.privacy_utility_framework.metrics.privacy_metrics.distance.nndr_class import NNDRCalculator\n","from privacy_utility_framework.privacy_utility_framework.metrics.privacy_metrics.distance.disco import DisclosureCalculator\n","\n","# Load original dataset\n","original_data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Tabula-main-claude/Real_Datasets/Adult.csv\")\n","# original_data.drop(columns=[\"index\"], inplace=True)\n","# original_data.drop(columns=[\"id\"], inplace=True)\n","original_name = \"adult\"\n","\n","# Directory containing synthetic datasets\n","synthetic_folder = \"/content/drive/MyDrive/Colab Notebooks/Tabula-main-claude/adult_syn_data\"\n","\n","# Dictionary to store aggregated results\n","aggregated_results = defaultdict(lambda: defaultdict(list))\n","\n","# Function to extract sigma value as float\n","def extract_sigma(file_name):\n","    match = re.search(r\"sigma-(\\d+)\", file_name)\n","    if match:\n","        sigma_str = match.group(1)\n","        if len(sigma_str) == 1:  # Single digit like \"1\" -> \"1\"\n","            return int(sigma_str)\n","        elif len(sigma_str) == 2:  # Two digits like \"05\" -> \"0.5\"\n","            return int(sigma_str) / 10\n","        elif len(sigma_str) == 3:  # Three digits like \"005\" -> \"0.05\"\n","            return int(sigma_str) / 100\n","    return None\n","\n","\n","# Loop through each synthetic file and perform calculations\n","for file_name in os.listdir(synthetic_folder):\n","    if file_name.endswith(\".csv\"):\n","        synthetic_path = os.path.join(synthetic_folder, file_name)\n","        synthetic_data = pd.read_csv(synthetic_path)\n","\n","        sigma = extract_sigma(file_name)\n","        if sigma is None:\n","            continue  # Skip files without a valid sigma value\n","\n","        synthetic_data = replace_outliers_with_mean(original_data, synthetic_data, sigma)\n","        # synthetic_data = remove_rows_with_outliers(original_data, synthetic_data, sigma)\n","        # Ensure correct data types (e.g., convert 'age' column to int if needed)\n","        for column in synthetic_data.columns:\n","            if column in original_data.columns:\n","                # Convert the column type in synthetic data to match the original data\n","                synthetic_data[column] = synthetic_data[column].astype(original_data[column].dtype)\n","\n","\n","        # print(f\"\\nProcessing synthetic dataset: {file_name} (sigma: {sigma})\")\n","\n","        # Utility Metric Calculation\n","        u = UtilityMetricManager()\n","        utility_metric_list = [\n","            BasicStatsCalculator(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","            # MICalculator(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","            # CorrelationCalculator(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","            # JSCalculator(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","        ]\n","        u.add_metric(utility_metric_list)\n","        results_utility = u.evaluate_all()\n","\n","        # Privacy Metric Calculation\n","        p = PrivacyMetricManager()\n","        privacy_metric_list = [\n","            DCRCalculator(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","            # NNDRCalculator(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","            # AdversarialAccuracyCalculator_NN(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","            # AdversarialAccuracyCalculator(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","        ]\n","        p.add_metric(privacy_metric_list)\n","        results_privacy = p.evaluate_all()\n","\n","        # # DiSCO and repU\n","        adult_keys = ['age', 'workclass', 'education', 'marital-status',\n","                      'occupation', 'relationship', 'race', 'gender', 'capital-gain',\n","                      'capital-loss', 'hours-per-week', 'native-country']\n","        adult_target = 'income' \n","\n","        calc = DisclosureCalculator(original_data, synthetic_data, keys=adult_keys, target=adult_target)\n","        repU, DiSCO = calc.evaluate()\n","\n","        # Aggregate metrics\n","        for key, value in {**results_utility, **results_privacy}.items():\n","            aggregated_results[sigma][key].append(value)\n","\n","\n","        aggregated_results[sigma][\"Disclosure_repU\"].append(repU)\n","        aggregated_results[sigma][\"Disclosure_DiSCO\"].append(DiSCO)\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":418,"status":"ok","timestamp":1734286696334,"user":{"displayName":"张泽昊","userId":"04308898238357121257"},"user_tz":-60},"id":"H8l6FENKMpVR"},"outputs":[],"source":["import numpy as np\n","# Calculate average metrics for each sigma\n","averaged_results = defaultdict(dict)\n","for sigma, metrics in aggregated_results.items():\n","    for metric, values in metrics.items():\n","        if isinstance(values[0], dict):\n","            averaged_results[sigma][metric] = {k: np.mean([v[k] for v in values]) for k in values[0]}\n","        else:\n","            averaged_results[sigma][metric] = np.mean(values)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":349,"status":"ok","timestamp":1734286699812,"user":{"displayName":"张泽昊","userId":"04308898238357121257"},"user_tz":-60},"id":"zTDyWJfkMpVR","outputId":"e65c287f-e52e-4e14-dd29-0abb2321daec"},"outputs":[{"name":"stdout","output_type":"stream","text":["    sigma       DCR      repU      DiSCO\n","0    0.00  0.186277  0.014332   0.016379\n","1    0.01  0.075474  3.527702  10.910692\n","2    0.02  0.092398  3.105933   8.777282\n","3    0.03  0.218609  0.014332   0.016379\n","4    0.04  0.254084  0.006142   0.010237\n","5    0.05  0.235138  0.008190   0.006142\n","6    0.10  0.302533  0.002047   0.002047\n","7    0.15  0.350046  0.006142   0.010237\n","8    0.20  0.204912  1.568322   4.547316\n","9    0.25  0.209828  1.394292   4.309815\n","10   0.30  0.292292  0.006142   0.004095\n","11   0.35  0.326677  0.004095   0.002047\n"]}],"source":["# Clean up averaged_results to extract metric names without file details\n","cleaned_results = defaultdict(dict)\n","\n","for sigma, metrics in averaged_results.items():\n","    for metric, value in metrics.items():\n","        # Extract only the metric name, ignoring dataset/file info\n","        metric_name = metric.split(\"(\")[0]\n","        if metric_name not in cleaned_results[sigma]:\n","            cleaned_results[sigma][metric_name] = []\n","        cleaned_results[sigma][metric_name].append(value)\n","\n","# Aggregate and calculate average values for cleaned results\n","final_results = defaultdict(dict)\n","for sigma, metrics in cleaned_results.items():\n","    for metric, values in metrics.items():\n","        if isinstance(values[0], dict):  # If metric value is a dictionary\n","            # Average each key in the dictionary\n","            final_results[sigma][metric] = {k: sum(v[k] for v in values) / len(values) for k in values[0]}\n","        else:  # If metric value is a list of scalars\n","            final_results[sigma][metric] = sum(values) / len(values)\n","\n","# Prepare data for plotting\n","data = {\n","    \"sigma\": sorted(final_results.keys()),\n","    \"DCR\": [final_results[sigma].get(\"DCRCalculator\", None) for sigma in sorted(final_results.keys())],\n","    # \"NNDR\": [final_results[sigma].get(\"NNDRCalculator\", None) for sigma in sorted(final_results.keys())],\n","    # \"AdversarialAccuracy\": [final_results[sigma].get(\"AdversarialAccuracyCalculator\", None) for sigma in sorted(final_results.keys())],\n","    # \"NNAA\": [final_results[sigma].get(\"AdversarialAccuracyCalculator_NN\", None) for sigma in sorted(final_results.keys())],\n","    # \"Correlation\": [final_results[sigma].get(\"CorrelationCalculator\", None) for sigma in sorted(final_results.keys())],\n","    # \"JS\": [final_results[sigma].get(\"JSCalculator\", None) for sigma in sorted(final_results.keys())],\n","    \"repU\": [final_results[sigma].get(\"Disclosure_repU\", None) for sigma in sorted(final_results.keys())],\n","    \"DiSCO\": [final_results[sigma].get(\"Disclosure_DiSCO\", None) for sigma in sorted(final_results.keys())],\n","}\n","\n","# Convert to DataFrame\n","df = pd.DataFrame(data)\n","\n","# Verify DataFrame content\n","print(df)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":358,"status":"ok","timestamp":1734286711580,"user":{"displayName":"张泽昊","userId":"04308898238357121257"},"user_tz":-60},"id":"hlAFD2tZMpVR","outputId":"f64a03ba-a117-4793-8753-b6d1edec7376"},"outputs":[{"name":"stdout","output_type":"stream","text":["    sigma      mean    median       var\n","0    0.25  0.026221  0.008968  0.011879\n","1    0.01  0.024460  0.006569  0.012641\n","2    0.05  0.043114  0.037042  0.013290\n","3    0.10  0.046519  0.034717  0.014424\n","4    0.15  0.054308  0.053231  0.015965\n","5    0.20  0.026352  0.006718  0.011874\n","6    0.30  0.048381  0.044074  0.013237\n","7    0.35  0.049159  0.040310  0.013305\n","8    0.02  0.024690  0.001715  0.012317\n","9    0.03  0.041696  0.036591  0.012565\n","10   0.04  0.044787  0.032641  0.014509\n","11   0.00  0.040666  0.051116  0.013012\n"]}],"source":["basic_stats_data = {\n","    \"sigma\": [],\n","    \"mean\": [],\n","    \"median\": [],\n","    \"var\": []\n","}\n","\n","for sigma, metrics in final_results.items():\n","    if \"BasicStatsCalculator\" in metrics:\n","        basic_stats = metrics[\"BasicStatsCalculator\"]\n","        basic_stats_data[\"sigma\"].append(sigma)\n","        basic_stats_data[\"mean\"].append(basic_stats[\"mean\"])\n","        basic_stats_data[\"median\"].append(basic_stats[\"median\"])\n","        basic_stats_data[\"var\"].append(basic_stats[\"var\"])\n","\n","# Convert to DataFrame\n","basic_stats_df = pd.DataFrame(basic_stats_data)\n","\n","# Display results\n","print(basic_stats_df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rpqxKvpeMpVR"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","datasets = df[\"sigma\"]\n","\n","# Privacy metrics\n","DCR = df[\"DCR\"]\n","adversarial_accuracy = df[\"NNAA\"]\n","\n","# Utility metrics\n","correlation = df[\"Correlation\"]\n","JS = df[\"JS\"]\n","\n","# Create subplots and first y-axis\n","fig, ax1 = plt.subplots(figsize=(14, 8))\n","\n","# Plot privacy metrics\n","ax1.plot(datasets, DCR, marker='o', color='red', label=\"DCR (Privacy)\", linestyle='-')\n","ax1.set_xlabel(\"Sigma Values\")\n","ax1.set_ylabel(\"Privacy Metrics\", color='red')\n","ax1.tick_params(axis='y', labelcolor='red')\n","\n","# Create another y-axis, plot utility metrics\n","ax2 = ax1.twinx()\n","ax2.plot(datasets, correlation, marker='^', color='blue', label=\"Correlation (Utility)\", linestyle='-')\n","ax2.plot(datasets, JS, marker='x', color='green', label=\"JS (Utility)\", linestyle='--')\n","ax2.plot(datasets, adversarial_accuracy, marker='s', color='orange', label=\"NNAA (Privacy)\", linestyle='--')\n","ax2.set_ylabel(\"Utility Metrics\", color='blue')\n","ax2.tick_params(axis='y', labelcolor='blue')\n","\n","# Add legend\n","lines, labels = ax1.get_legend_handles_labels()\n","lines2, labels2 = ax2.get_legend_handles_labels()\n","ax1.legend(lines + lines2, labels + labels2, loc='upper right')\n","\n","# Add title\n","plt.title(\"Privacy vs Utility Metrics across Sigma Values\")\n","plt.xticks(rotation=45)\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"LDLr-bozMswf"},"source":["### remove"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":1953386,"status":"ok","timestamp":1734288730674,"user":{"displayName":"张泽昊","userId":"04308898238357121257"},"user_tz":-60},"id":"MSVRuDP7MuGV","outputId":"25c33cbb-715a-4824-b3b4-29894df26a45"},"outputs":[{"name":"stdout","output_type":"stream","text":["Under 0.25, removed 3652 rows with outliers.\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 69852 columns.\n","IDENTITY: \n","         UiO        UiS     UiOiS      repU\n","0  77.122149  79.491413  1.791491  1.326727\n","ATTRIBUTES: \n","       Dorig      Dsyn        iS       DiS     DiSCO    DiSDiO  max_denom  \\\n","0  92.070349  89.04915  8.177388  6.146349  4.127595  2.598174       20.0   \n","\n","   mean_denom  \n","0     1.99604  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n","Under 0.01, removed 378 rows with outliers.\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 62762 columns.\n","IDENTITY: \n","         UiO        UiS     UiOiS      repU\n","0  77.122149  54.394395  5.661111  3.509275\n","ATTRIBUTES: \n","       Dorig       Dsyn         iS        DiS     DiSCO    DiSDiO  max_denom  \\\n","0  92.070349  75.876982  20.019655  13.166946  10.88817  9.827607       19.0   \n","\n","   mean_denom  \n","0    1.713825  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n","Under 0.05, removed 1767 rows with outliers.\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 70531 columns.\n","IDENTITY: \n","         UiO        UiS     UiOiS      repU\n","0  77.122149  67.063733  0.014332  0.010237\n","ATTRIBUTES: \n","       Dorig       Dsyn        iS       DiS    DiSCO   DiSDiO  max_denom  \\\n","0  92.070349  80.029582  0.014332  0.010237  0.00819  0.00819        1.0   \n","\n","   mean_denom  \n","0         1.0  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n","Under 0.1, removed 2674 rows with outliers.\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 72021 columns.\n","IDENTITY: \n","         UiO        UiS     UiOiS      repU\n","0  77.122149  75.190882  0.004095  0.002047\n","ATTRIBUTES: \n","       Dorig       Dsyn        iS       DiS     DiSCO    DiSDiO  max_denom  \\\n","0  92.070349  86.391101  0.004095  0.004095  0.004095  0.004095        1.0   \n","\n","   mean_denom  \n","0         1.0  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n","Under 0.15, removed 3086 rows with outliers.\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 72216 columns.\n","IDENTITY: \n","         UiO        UiS     UiOiS      repU\n","0  77.122149  78.038821  0.004095  0.004095\n","ATTRIBUTES: \n","       Dorig       Dsyn        iS       DiS    DiSCO    DiSDiO  max_denom  \\\n","0  92.070349  87.934217  0.010237  0.010237  0.00819  0.004095        2.0   \n","\n","   mean_denom  \n","0    1.333333  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n","Under 0.2, removed 3332 rows with outliers.\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 70086 columns.\n","IDENTITY: \n","         UiO        UiS     UiOiS      repU\n","0  77.122149  78.663144  1.981901  1.510995\n","ATTRIBUTES: \n","       Dorig       Dsyn        iS      DiS    DiSCO    DiSDiO  max_denom  \\\n","0  92.070349  88.827339  8.738381  6.51898  4.44085  3.073175       18.0   \n","\n","   mean_denom  \n","0    1.889373  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n","Under 0.3, removed 3980 rows with outliers.\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 71420 columns.\n","IDENTITY: \n","         UiO        UiS    UiOiS      repU\n","0  77.122149  81.093589  0.00819  0.006142\n","ATTRIBUTES: \n","       Dorig       Dsyn       iS       DiS     DiSCO    DiSDiO  max_denom  \\\n","0  92.070349  90.871039  0.00819  0.006142  0.004095  0.004095        1.0   \n","\n","   mean_denom  \n","0         1.0  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n","Under 0.35, removed 4387 rows with outliers.\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 70999 columns.\n","IDENTITY: \n","         UiO       UiS     UiOiS      repU\n","0  77.122149  83.02219  0.004095  0.004095\n","ATTRIBUTES: \n","       Dorig      Dsyn        iS       DiS     DiSCO    DiSDiO  max_denom  \\\n","0  92.070349  91.69171  0.004095  0.004095  0.002047  0.002047        1.0   \n","\n","   mean_denom  \n","0         1.0  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n","Under 0.02, removed 772 rows with outliers.\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 64700 columns.\n","IDENTITY: \n","         UiO        UiS     UiOiS      repU\n","0  77.122149  59.125189  4.962942  3.101839\n","ATTRIBUTES: \n","       Dorig      Dsyn         iS        DiS     DiSCO    DiSDiO  max_denom  \\\n","0  92.070349  75.68832  17.661029  10.982351  8.775234  7.884608       19.0   \n","\n","   mean_denom  \n","0    1.728226  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n","Under 0.03, removed 1141 rows with outliers.\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 69624 columns.\n","IDENTITY: \n","         UiO        UiS     UiOiS      repU\n","0  77.122149  62.595657  0.022522  0.014332\n","ATTRIBUTES: \n","       Dorig       Dsyn        iS       DiS     DiSCO    DiSDiO  max_denom  \\\n","0  92.070349  77.474147  0.022522  0.020474  0.016379  0.016379        1.0   \n","\n","   mean_denom  \n","0         1.0  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n","Under 0.04, removed 1412 rows with outliers.\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 70220 columns.\n","IDENTITY: \n","         UiO        UiS     UiOiS      repU\n","0  77.122149  65.179318  0.006142  0.006142\n","ATTRIBUTES: \n","       Dorig      Dsyn        iS       DiS     DiSCO    DiSDiO  max_denom  \\\n","0  92.070349  78.70138  0.020474  0.020474  0.010237  0.010237        2.0   \n","\n","   mean_denom  \n","0        1.25  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n","Under 0, removed 36 rows with outliers.\n","Synthetic and original data checked with synorig.compare,\n"," looks like no adjustment needed\n","\n","\n","-------------------Synthesis 1--------------------\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/synprivutil-main/privacy_utility_framework/privacy_utility_framework/metrics/privacy_metrics/distance/disco.py:274: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  syndata[j][col] = syndata[j][col].astype('category')\n"]},{"name":"stdout","output_type":"stream","text":["Table for target income from GT alone with keys has 2 rows and 41439 columns.\n","Table for target income from GT & SD with all key combinations has 2 rows and 66497 columns.\n","IDENTITY: \n","         UiO        UiS     UiOiS      repU\n","0  77.122149  38.194264  0.020474  0.014332\n","ATTRIBUTES: \n","       Dorig       Dsyn        iS       DiS     DiSCO    DiSDiO  max_denom  \\\n","0  92.070349  71.653023  0.020474  0.016379  0.016379  0.016379        1.0   \n","\n","   mean_denom  \n","0         1.0  \n","~~~~~~~~~~~~~~~ Done ~~~~~~~~~~~~~~~\n"]}],"source":["import os\n","import re\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from collections import defaultdict\n","from sklearn.preprocessing import MinMaxScaler\n","from privacy_utility_framework.privacy_utility_framework.metrics.utility_metrics.utility_metric_manager import UtilityMetricManager\n","from privacy_utility_framework.privacy_utility_framework.metrics.utility_metrics.statistical.basic_stats import BasicStatsCalculator\n","from privacy_utility_framework.privacy_utility_framework.metrics.utility_metrics.statistical.mutual_information import MICalculator\n","from privacy_utility_framework.privacy_utility_framework.metrics.utility_metrics.statistical.correlation import CorrelationCalculator\n","from privacy_utility_framework.privacy_utility_framework.metrics.utility_metrics.statistical.js_similarity import JSCalculator\n","from privacy_utility_framework.privacy_utility_framework.metrics.privacy_metrics.privacy_metric_manager import PrivacyMetricManager\n","from privacy_utility_framework.privacy_utility_framework.metrics.privacy_metrics.distance.adversarial_accuracy_class import AdversarialAccuracyCalculator, AdversarialAccuracyCalculator_NN\n","from privacy_utility_framework.privacy_utility_framework.metrics.privacy_metrics.distance.dcr_class import DCRCalculator\n","from privacy_utility_framework.privacy_utility_framework.metrics.privacy_metrics.distance.nndr_class import NNDRCalculator\n","from privacy_utility_framework.privacy_utility_framework.metrics.privacy_metrics.distance.disco import DisclosureCalculator\n","\n","# Load original dataset\n","original_data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Tabula-main-claude/Real_Datasets/Adult.csv\")\n","# original_data.drop(columns=[\"index\"], inplace=True)\n","# original_data.drop(columns=[\"id\"], inplace=True)\n","original_name = \"adult\"\n","\n","# Directory containing synthetic datasets\n","synthetic_folder = \"/content/drive/MyDrive/Colab Notebooks/Tabula-main-claude/adult_syn_data\"\n","\n","# Dictionary to store aggregated results\n","aggregated_results = defaultdict(lambda: defaultdict(list))\n","\n","# Function to extract sigma value as float\n","def extract_sigma(file_name):\n","    match = re.search(r\"sigma-(\\d+)\", file_name)\n","    if match:\n","        sigma_str = match.group(1)\n","        if len(sigma_str) == 1:  # Single digit like \"1\" -> \"1\"\n","            return int(sigma_str)\n","        elif len(sigma_str) == 2:  # Two digits like \"05\" -> \"0.5\"\n","            return int(sigma_str) / 10\n","        elif len(sigma_str) == 3:  # Three digits like \"005\" -> \"0.05\"\n","            return int(sigma_str) / 100\n","    return None\n","\n","\n","# Loop through each synthetic file and perform calculations\n","for file_name in os.listdir(synthetic_folder):\n","    if file_name.endswith(\".csv\"):\n","        synthetic_path = os.path.join(synthetic_folder, file_name)\n","        synthetic_data = pd.read_csv(synthetic_path)\n","\n","        sigma = extract_sigma(file_name)\n","        if sigma is None:\n","            continue  # Skip files without a valid sigma value\n","\n","        # synthetic_data = replace_outliers_with_mean(original_data, synthetic_data, sigma)\n","        synthetic_data = remove_rows_with_outliers(original_data, synthetic_data, sigma)\n","        # Ensure correct data types (e.g., convert 'age' column to int if needed)\n","        for column in synthetic_data.columns:\n","            if column in original_data.columns:\n","                # Convert the column type in synthetic data to match the original data\n","                synthetic_data[column] = synthetic_data[column].astype(original_data[column].dtype)\n","\n","\n","        # print(f\"\\nProcessing synthetic dataset: {file_name} (sigma: {sigma})\")\n","\n","        # Utility Metric Calculation\n","        u = UtilityMetricManager()\n","        utility_metric_list = [\n","            BasicStatsCalculator(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","            # MICalculator(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","            # CorrelationCalculator(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","            # JSCalculator(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","        ]\n","        u.add_metric(utility_metric_list)\n","        results_utility = u.evaluate_all()\n","\n","        # Privacy Metric Calculation\n","        p = PrivacyMetricManager()\n","        privacy_metric_list = [\n","            DCRCalculator(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","            # NNDRCalculator(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","            # AdversarialAccuracyCalculator_NN(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","            # AdversarialAccuracyCalculator(original_data, synthetic_data, original_name=original_name, synthetic_name=file_name),\n","        ]\n","        p.add_metric(privacy_metric_list)\n","        results_privacy = p.evaluate_all()\n","\n","        # # DiSCO and repU\n","        adult_keys = ['age', 'workclass', 'education', 'marital-status',\n","                      'occupation', 'relationship', 'race', 'gender', 'capital-gain',\n","                      'capital-loss', 'hours-per-week', 'native-country']\n","        adult_target = 'income'  \n","\n","        calc = DisclosureCalculator(original_data, synthetic_data, keys=adult_keys, target=adult_target)\n","        repU, DiSCO = calc.evaluate()\n","\n","        # Aggregate metrics\n","        for key, value in {**results_utility, **results_privacy}.items():\n","            aggregated_results[sigma][key].append(value)\n","\n","\n","        aggregated_results[sigma][\"Disclosure_repU\"].append(repU)\n","        aggregated_results[sigma][\"Disclosure_DiSCO\"].append(DiSCO)\n","\n"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1734289129992,"user":{"displayName":"张泽昊","userId":"04308898238357121257"},"user_tz":-60},"id":"YdlxXIvWMuGV"},"outputs":[],"source":["import numpy as np\n","# Calculate average metrics for each sigma\n","averaged_results = defaultdict(dict)\n","for sigma, metrics in aggregated_results.items():\n","    for metric, values in metrics.items():\n","        if isinstance(values[0], dict):\n","            averaged_results[sigma][metric] = {k: np.mean([v[k] for v in values]) for k in values[0]}\n","        else:\n","            averaged_results[sigma][metric] = np.mean(values)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":357,"status":"ok","timestamp":1734289131647,"user":{"displayName":"张泽昊","userId":"04308898238357121257"},"user_tz":-60},"id":"Qch24PFAMuGV","outputId":"242fb1f8-c461-44b3-e50b-5d0ec393c172"},"outputs":[{"name":"stdout","output_type":"stream","text":["    sigma       DCR  NNAA Correlation    JS      repU      DiSCO\n","0    0.00  0.186265  None        None  None  0.014332   0.016379\n","1    0.01  0.075491  None        None  None  3.509275  10.888170\n","2    0.02  0.092569  None        None  None  3.101839   8.775234\n","3    0.03  0.218704  None        None  None  0.014332   0.016379\n","4    0.04  0.254419  None        None  None  0.006142   0.010237\n","5    0.05  0.235289  None        None  None  0.010237   0.008190\n","6    0.10  0.303368  None        None  None  0.002047   0.004095\n","7    0.15  0.351083  None        None  None  0.004095   0.008190\n","8    0.20  0.206036  None        None  None  1.510995   4.440850\n","9    0.25  0.211020  None        None  None  1.326727   4.127595\n","10   0.30  0.293553  None        None  None  0.006142   0.004095\n","11   0.35  0.328640  None        None  None  0.004095   0.002047\n"]}],"source":["# Clean up averaged_results to extract metric names without file details\n","cleaned_results = defaultdict(dict)\n","\n","for sigma, metrics in averaged_results.items():\n","    for metric, value in metrics.items():\n","        # Extract only the metric name, ignoring dataset/file info\n","        metric_name = metric.split(\"(\")[0]\n","        if metric_name not in cleaned_results[sigma]:\n","            cleaned_results[sigma][metric_name] = []\n","        cleaned_results[sigma][metric_name].append(value)\n","\n","# Aggregate and calculate average values for cleaned results\n","final_results = defaultdict(dict)\n","for sigma, metrics in cleaned_results.items():\n","    for metric, values in metrics.items():\n","        if isinstance(values[0], dict):  # If metric value is a dictionary\n","            # Average each key in the dictionary\n","            final_results[sigma][metric] = {k: sum(v[k] for v in values) / len(values) for k in values[0]}\n","        else:  # If metric value is a list of scalars\n","            final_results[sigma][metric] = sum(values) / len(values)\n","\n","# Prepare data for plotting\n","data = {\n","    \"sigma\": sorted(final_results.keys()),\n","    \"DCR\": [final_results[sigma].get(\"DCRCalculator\", None) for sigma in sorted(final_results.keys())],\n","    # \"NNDR\": [final_results[sigma].get(\"NNDRCalculator\", None) for sigma in sorted(final_results.keys())],\n","    # \"AdversarialAccuracy\": [final_results[sigma].get(\"AdversarialAccuracyCalculator\", None) for sigma in sorted(final_results.keys())],\n","    \"NNAA\": [final_results[sigma].get(\"AdversarialAccuracyCalculator_NN\", None) for sigma in sorted(final_results.keys())],\n","    \"Correlation\": [final_results[sigma].get(\"CorrelationCalculator\", None) for sigma in sorted(final_results.keys())],\n","    \"JS\": [final_results[sigma].get(\"JSCalculator\", None) for sigma in sorted(final_results.keys())],\n","    \"repU\": [final_results[sigma].get(\"Disclosure_repU\", None) for sigma in sorted(final_results.keys())],\n","    \"DiSCO\": [final_results[sigma].get(\"Disclosure_DiSCO\", None) for sigma in sorted(final_results.keys())],\n","}\n","\n","# Convert to DataFrame\n","df = pd.DataFrame(data)\n","\n","# Verify DataFrame content\n","print(df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"0Zs0Jd-XMuGW"},"outputs":[],"source":["basic_stats_data = {\n","    \"sigma\": [],\n","    \"mean\": [],\n","    \"median\": [],\n","    \"var\": []\n","}\n","\n","for sigma, metrics in final_results.items():\n","    if \"BasicStatsCalculator\" in metrics:\n","        basic_stats = metrics[\"BasicStatsCalculator\"]\n","        basic_stats_data[\"sigma\"].append(sigma)\n","        basic_stats_data[\"mean\"].append(basic_stats[\"mean\"])\n","        basic_stats_data[\"median\"].append(basic_stats[\"median\"])\n","        basic_stats_data[\"var\"].append(basic_stats[\"var\"])\n","\n","basic_stats_df = pd.DataFrame(basic_stats_data)\n","\n","print(basic_stats_df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Mkzfjf-ZMuGW"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","datasets = df[\"sigma\"]\n","\n","DCR = df[\"DCR\"]\n","adversarial_accuracy = df[\"NNAA\"]\n","\n","correlation = df[\"Correlation\"]\n","JS = df[\"JS\"]\n","\n","fig, ax1 = plt.subplots(figsize=(14, 8))\n","\n","ax1.plot(datasets, DCR, marker='o', color='red', label=\"DCR (Privacy)\", linestyle='-')\n","ax1.set_xlabel(\"Sigma Values\")\n","ax1.set_ylabel(\"Privacy Metrics\", color='red')\n","ax1.tick_params(axis='y', labelcolor='red')\n","\n","ax2 = ax1.twinx()\n","ax2.plot(datasets, correlation, marker='^', color='blue', label=\"Correlation (Utility)\", linestyle='-')\n","ax2.plot(datasets, JS, marker='x', color='green', label=\"JS (Utility)\", linestyle='--')\n","ax2.plot(datasets, adversarial_accuracy, marker='s', color='orange', label=\"NNAA (Privacy)\", linestyle='--')\n","ax2.set_ylabel(\"Utility Metrics\", color='blue')\n","ax2.tick_params(axis='y', labelcolor='blue')\n","\n","lines, labels = ax1.get_legend_handles_labels()\n","lines2, labels2 = ax2.get_legend_handles_labels()\n","ax1.legend(lines + lines2, labels + labels2, loc='upper right')\n","\n","plt.title(\"Privacy vs Utility Metrics across Sigma Values\")\n","plt.xticks(rotation=45)\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"ijLWRNypOzsN"},"source":["## Comparison"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"I1MQt9tdE0-t"},"outputs":[],"source":["import os\n","import re\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","def extract_sigma(file_name):\n","    match = re.search(r\"sigma-(\\d+)\", file_name)\n","    if match:\n","        sigma_str = match.group(1)\n","        if len(sigma_str) == 1:  # Single digit like \"1\" -> \"1\"\n","            return int(sigma_str)\n","        elif len(sigma_str) == 2:  # Two digits like \"05\" -> \"0.5\"\n","            return int(sigma_str) / 10\n","        elif len(sigma_str) == 3:  # Three digits like \"005\" -> \"0.05\"\n","            return int(sigma_str) / 100\n","    return None\n","\n","\n","\n","def plot_comparison_for_each_column(original_data, synthetic_folder):\n","    \"\"\"\n","    For each column, plot synthetic data with different sigma values against original data.\n","    \"\"\"\n","    synthetic_files = [\n","        (file_name, extract_sigma(file_name))\n","        for file_name in os.listdir(synthetic_folder)\n","        if file_name.endswith(\".csv\") and extract_sigma(file_name) is not None\n","    ]\n","\n","    # Sort files by sigma\n","    synthetic_files = sorted(synthetic_files, key=lambda x: x[1])\n","\n","    # Iterate over each column\n","    for column in original_data.columns:\n","        # Adjust the number of rows and columns in the subplot grid\n","        num_files = len(synthetic_files)\n","        ncols = 3\n","        nrows = (num_files + ncols - 1) // ncols  # Ceiling division for rows\n","\n","        fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 2 * nrows))\n","\n","        # Flatten axes array for easy indexing\n","        axes = axes.flatten()\n","\n","        for i, (file_name, sigma) in enumerate(synthetic_files):\n","            synthetic_path = os.path.join(synthetic_folder, file_name)\n","            synthetic_data = pd.read_csv(synthetic_path)\n","            # synthetic_data = replace_outliers_with_mean(original_data, synthetic_data, sigma)\n","            synthetic_data = remove_rows_with_outliers(original_data, synthetic_data, sigma)\n","            # Plot original and synthetic distributions\n","            sns.kdeplot(original_data[column], ax=axes[i], label='Original', color='blue')\n","            if column in synthetic_data.columns:\n","                sns.kdeplot(synthetic_data[column], ax=axes[i], label=f'Sigma {sigma}', color='red', alpha=0.3)\n","\n","            axes[i].set_title(f'Sigma {sigma}', fontsize=6)\n","            axes[i].legend(fontsize=5)\n","            axes[i].tick_params(axis='both', which='major', labelsize=5)\n","\n","        # Hide unused subplots\n","        for j in range(len(synthetic_files), len(axes)):\n","            axes[j].axis('off')\n","\n","        fig.suptitle(f'Distribution of {column}', fontsize=14)\n","        plt.tight_layout()\n","        plt.show()\n","\n","\n","\n","# Load original dataset\n","original_data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Tabula-main-claude/Real_Datasets/Adult.csv\")\n","\n","# Path to synthetic datasets folder\n","synthetic_folder = \"/content/drive/MyDrive/Colab Notebooks/Tabula-main-claude/adult_syn_data\"\n","\n","# Generate plots\n","plot_comparison_for_each_column(original_data, synthetic_folder)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMGlFFXI4edR7Oz2PbC8Jam","collapsed_sections":["IKivqkgQ9mvI"],"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
